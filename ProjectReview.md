# Project Review
## Front End Part
### Technology Stack
### Reusable Component
### Package
- We use UglifyJS to minify code, as it removes whitespace and unnecessary characters within a file to make it smaller and thus, load faster. It also provide options to remove unreachable code and reduce variables/property characters. However Uglify will not auto obfuscate your code, it has mangle options and you need to manually set it, also remember to close warning and sorceMap on Prod.  
- For versions,  DefinePlugin replaces variables in code with other values or expressions at compile time, so we add it at the bottom of plugins to replace versionHash, env options and path. And we change output chunkFileName to include versionHash, which will update chunk name each time we deploy for version management and avoid cache-control issue(default will be no-cache and return 304 Not Modified when assets name don't change [See more: http caching](https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching)).  
- On devServer, we can set allowed hosts and headers (control access methods like get post put delete, origin and headers like x-requested-with, content-type). And we can set proxy for api and static request, direct them to target server and use bypass to config certain url.   
- Before webpack V4 we used CommonsChunkPlugin, chunks (and modules imported inside them) were connected by a parent-child relationship in the internal webpack graph. The CommonsChunkPlugin was used to avoid duplicated dependencies across them. Common chunked file can be loaded once initially, and stored in cache for later use.  Now we have optimization.splitChunks, Webpack will automatically split chunks if it's shared or too large, and provide severel options including which chunk to optimize, minChunk, chacheGroups and so on.    
- We use webpack-split-by-path to split chunk, we don't use webpack auto split since we have some dynamic dependency, we require some JS file manually. Webpack-split-by-path will package all path array files to named chunk, and it starts from the top, files will only been packaged once, so we can package base chunk at the bottom, and the index.js will only load a small scale base chunk.  
[See more: Webpack official code-splitting](https://webpack.js.org/guides/code-splitting/ )  
[See more: The 100% correct way to split your chunks with Webpack](https://medium.com/hackernoon/the-100-correct-way-to-split-your-chunks-with-webpack-f8a9df5b7758 )  
- Besides, we use bundle analyzer to analyze each chunk's size and try to split large ones. And use copyWebpackPlugin to move images/font folder to build path(Starting in version 3.0.0, copyWebpackPlugin stopped using filesystem to copy files and depending on webpack's in-memory fs, when use webpack-dev-server, you need to force it with the write-file-webpack-plugin.) And we need license-webpack-plugin to outputs licenses from 3rd party libraries to a file, this can also be used to filter certain license type like MIT. LoaderOptionsPlugin is added to set minimize and debug options base on env.
- For small scale projects, like PDF UI generator, we can direcly use Create React App, it will auto config a react application with all react dependencies, scss support, eslint/prettier and even unit testing driven by Jest. When you run create-react-app it goto node.js file tasks/cra.js, which use fs, path and child_process to add customized packages into packageJson, and then it will call create-react-app/index.js that only checks your node version and init createReactApp.js.  They use semver to check package version(format legal check, themplate version supprt check and compare to latest), write seperate logic for yarn, run default or customized template, then use node comand to install all packages.  However there are many disadvantages, especially you can't use webpack.config.js, you have to use libraries like customize-cra or react-app-rewired which have limited capabilities to change build settings.  I did write config-overrides.js to change build path since I need to seperate package for header and footer, the syntax is different with webpack and they don't provide a nice doc. So don't use CRA when you need to custom build config.
![Image](https://github.com/MichelleGuan/Blog/blob/main/images/createReactApp.png)
### Routing
We use marionette route on old project and use react route on next-stage.
### Internationalization
On old project, we load certain terms and config after get countryCode and language through start.js, which comes from URL, and use moments to do time Internationalization. Whereas on pure react app, we can simply use react-intl.
### Theming
We did theming trough a dramatizing way. We add comments(//##include-theme##) on scss code, for variables like breakpoints, which based on country, we will build all country's variables in and genetate to different country's scss code in one file. So we can then use the certain counrty's scss code start with it's class.  
### Security
- We didn't use restful API, and currently there's only 200 code on old project, all error messsages will include in success message. This is mainly cause by the secure concern, since if we provide detailed error message on error code including 500/403, the attacker might infer our file stucture or find security holes. But from my option, we can just give a cutomized not found page, which already exist, no matter the error code, and follow restful API.
- We did add human identification to avoide dos attack, and doing encryption for user info(HTTPs itself only encrypt public key). For CSRF, we use tocken solution, on all reset operations we will add csrf tocken for few incoming instruct through Ajax setup (we can also add set-cookie:same site, or check origin/refer header, or double check the cookie). Also on server side we have white list.
- For cookieXSS, which attacker might include JS files though cookie, we can simply set cookie to HTTPs only, and block Javascript access cookie. For HTTP man-in-the-middle attack, we did have a VPN on company level, multi-factor authentication also works.
- Besides, all input length should be limited and FE should check the input type and validity before send it to BE. Also we should limit URL length on cloud level, and avoide store sensitive message on FE, expecially on cookie storage, since it is send to BE each request.
### Data Flow
- On our project, front-end did many data proceccing work, we handle sitemap and articles, and for some sites, we even use two different sitemaps depeneds on user roles. For fund data, front-end recieve all fund data array on listing page and all certain fund infos on detail pages, thus we have data proxys and services to sort and process data to structures we can render. This is due to the limitations of back-end design since it's a really old project, but the good thing is, when you doing fund search or article filter, it can be super fast, since they are all memorized on cache after first request. On all new writtern components data layer and UI layer are seperated, so we can directly migrate UI part to new project.
- The original project use redux on complex react component like chart compare, and we use saga to handle asynchronous state. I don't think redux is the best state management library for react, although it can gurentee the predictable of state. Redux is not good at manage asynchronous state and we have to include saga or thunk for that, if you only want to manage synchronize state cross components, contextAPI and hooks are way more enough. On top of that, Redux is an in-memory state store, so if application crashes, you will lose entire application state, which means that you have to use a caching solution to create a backup of your application state, which again creates extra overhead. By the way, react is an unidirection data flow framework, so for single souce data component we don't need to do state management.  
- On next-state project we use Rxjs, and maybe Redux-Observable which is a redux solution based on Rxjs in the future. RxJS is a library composing asynchronous and event-based programs using observable sequences. It provides Observable, satellite types (Observer, Schedulers, Subjects) and operators (map, filter, reduce, every, etc) to allow handling asynchronous events as collections. On backbone.js we have event on and trigger, but it's more like a syntactic sugar for eventListener, if you need to trigger a callback after several asynchronous states ready, you still need to use setInterval or requestAnimationFrame or doing counts after each trigger. Rxjs just packing them, and allow you to handle event as collections while providing many powerful methods. Moreover, it's easy to do unit testing with TestScheduler, you only need to check whether states in collections are what you expected, other async things are all handled by frameworks, otherwise you will need to write unit testing for event listener, setInterval or requestAnimationFrame.
[See more: Building Reactive Apps with Redux, RxJS, and Redux-Observable in React Native](https://www.toptal.com/react-native/react-redux-rxjs-tutorial)
### Unit testing
 - We using Karma(execute JavaScript code in multiple real browsers using istanbul), mocha, chai and react test library. The reason we don't choose Jest, is to support marionette/backbone.
 - Usually we only need to use expect and assert to check result, describe testing functions and use 'it' for each conditions. To test UI, we render react with @testing-library/react, and use beforeEach/ afterEach hooks to create testing dom, which will run on each condition. Inside chai.js expect() method, we can write all dom operartions, even syntax not supported by chai.js. We also use snapshot to track UI changes. Persionally I don't like chai, since it even not support Map, Set or WeakMap, and we have to do work around.
 - We can use renderHook that has three return values: result, rerender, unmount, to test react customized hooks. However rerender can't been called after unmount, and it don't contain any destory method, so I have to test some conditions on components use this hook.
 - Also we have sinon to check if a callback is trigged, and fireEvent to mock most events. If you want to test a result after few mimutes, you can create Promise contains setTimeOut and use async await.
## CMS Part
 - Django CMS has build-in admin page and permission system, and can intergrate Front-end enverionment for preview(currently native JS CSS and gulp, we can also use react, scss, webpack and so on as I tested). We write addon including model.py that generate SQL to update postgreSQL, and admin.py to edit CMS management page, and app.py for specific bussiness logic. Addons are small features that can be set to certain type articles, publisher can choose and edit them, for example, a sticky-footer addon can be used on common articles, after publisher edit and deploy content, django CMS will stored them to database follow model.py parttern, and then all data stored will be generate to a XML formated as setting and set to back-end.   
 - We use docker to provide container service and doing packge through conmand docker-compose build, which will generate init.py. Divio cloud will take all package job, and all static resource like image will be intercepted after publisher deplopy articles, they will be sent to AWS target site for CDN. We also use rabbitMQ since we have several server(actually four), and add job like edit articles might be duplicated. We set up different CMS sites for each country, for common articles, they are stored in master site. Currently we use Urban Deploy and as metioned, static resource will be sent to AWS(will have cache issue) while others are updated to Back-end database.
## Deploy and Cloud
- As other front-end projects, we use es-lint and prettier, and use git hooks---husky to do pre-commit check, this is to guarantee the commited code will follow the team criterion. And use commintLint to check the commit message, to bind all commits with Jira tickets (agile board management platform).
- The build will auto start, after commit and tag on triggered branchs. On bamboo build Unit testing will run, and after generated zip file, it will auto uploaded to nexus. Then bamboo will sent a message to AWS, which will use S3 code build API and deploy code to target sites.
- On AWS the cloudFront is the project entry, we do redirect and CDN here. You can set several request regular expressions and write lambda functions to handle them. For example, we will check user agent and send crawel result for social media, and on PDF generate APIs we will request fund data and run PDF services.
